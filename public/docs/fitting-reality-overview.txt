# **Introduction**

This work reflects the artist’s critical consideration of how contemporary artificial intelligence collects, processes, and re-expresses human information.

It is an interactive spatial artwork developed on **TouchDesigner**, technically integrating real-time point cloud modeling, audience data capture, and the operation of locally run generative image models.

---

# **Project Concept**

In recent years, with the rapid advancement of large-scale AI models and the proliferation of open-source alternatives, one clear trend has emerged: within the logic of capital markets, the *value of algorithms themselves is decreasing*, while the validity and scale of **training data** are being prioritized.

Take Tesla’s autonomous driving system as an example: its onboard AI relies on a vast and continuously updated “world model.” To sustain this, Tesla employs an ostensibly simple but remarkably effective approach—using each vehicle’s onboard cameras to collect road images, which are then filtered, compressed, and encrypted before being transmitted back to Tesla’s data centers for iterative model training.

This pattern may appear ordinary in daily life, yet it reflects a deeper logic of exploiting users’ unconscious contributions. Similarly, Google’s **reCAPTCHA** system, initially designed to block automated abuse, now quietly transforms users into “free data-labeling workers,” providing invaluable training data for AI image recognition.

Such methods of **capturing and exploiting behavioral data without explicit user awareness** constitute what can be called *technological exploitation*. This is no isolated case; rather, it has permeated nearly every aspect of human daily life by 2025. This work seeks to critically engage with this phenomenon.

Furthermore, whether obtained through legal or questionable means, the collection and use of behavioral data for AI training appears increasingly irreversible. Once trained, these models are repackaged and reintroduced into the market, sold as creative tools. Ironically, the creators who use these tools may be generating works built on datasets that partially derive from their own or their peers’ contributions.

Thus, creators, empowered by such low-cost tools, produce cheaper outputs compared to traditional methods, feeding them back into public circulation as entertainment commodities.

This cycle, while efficient, exacerbates the logic of **technological domination**: it undermines creative subjectivity on the one hand, and on the other, it provides “bread and circuses” at ever-lower costs—masking a deep cognitive crisis beneath a surface of instant entertainment. For businesses, this algorithm-driven productivity perfectly aligns with commercial logic; for the public, however, the decline of creative costs risks **seriously distorting perception and understanding of reality**.

This critique strongly resonates with Walter Lippmann’s arguments in *Public Opinion* (1922). Lippmann proposed that in modern democracies, the public does not perceive reality directly but rather through a *“pseudo-environment”* constructed by media: images shape stereotypes, stereotypes shape opinion, and opinion wields powerful emotional influence. Today’s generative AI intensifies this dynamic: “prompts” produce outputs that increasingly approximate reality, making low-cost but highly effective constructions of “secondary reality.” This process challenges the very foundations of public cognition at unprecedented speed and scale.

This project, therefore, aims to create a **“data loop”**: audience behavior and information are captured, transformed, and regenerated by AI, then projected back into their bodies and the shared space. The process operates both as an abstract metaphor for the logic of “data in, entertainment out” and as a spatialized visualization of how technological mediation distorts collective perception.